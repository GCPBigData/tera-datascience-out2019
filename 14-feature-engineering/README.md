# Pré Aula

Os tópicos 1 e 2 e 4 são *obrigatórios* para entender as diferentes técnicas aplicadas. O tópico 5 ajudará a entender melhor os diversos scaleres do sklearn e quando utilizá-los.

### Serie de blog posts sobre feature engineering

[1 - Variaveis contínuas](https://towardsdatascience.com/understanding-feature-engineering-part-1-continuous-numeric-data-da4e47099a7b)
[2 - Variáveis categoricas](https://towardsdatascience.com/understanding-feature-engineering-part-2-categorical-data-f54324193e63)
[3 - Lidando com textos](https://towardsdatascience.com/understanding-feature-engineering-part-3-traditional-methods-for-text-data-f6f7d70acd41)

### Comparação de diferentes scalers

[4 -Porque precisamos normalizar/padronizar atributos, com exemplos](https://medium.com/@contactsunny/why-do-we-need-feature-scaling-in-machine-learning-and-how-to-do-it-using-scikit-learn-d8314206fe73)

[5 - Comparação MUITO legal dos diferentes scalers do sklearn](https://scikit-learn.org/stable/auto_examples/preprocessing/plot_all_scaling.html)

[6 - MinMax video](https://www.youtube.com/watch?v=jOxS1eJRsOk)
[7 - ZScore video](https://www.youtube.com/watch?v=1o-t_mVDDYQ)

### Variáveis categoricas (mais detalhes)

[8 - Mais detalhes sobre variáveis categóricas](https://www.datacamp.com/community/tutorials/categorical-data)(Similar ao 2)
