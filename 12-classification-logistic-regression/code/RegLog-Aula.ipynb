{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algoritmos de Classificação: Regressão Logística"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nós vamos utilizar o dataset Bank Marketing disponibilizado no [site da UCI](http://archive.ics.uci.edu/ml/datasets/Bank+Marketing). Utilizaremos uma versão adaptada para os objetivos da aula e disponível na pasta `data`.\n",
    "\n",
    "> The data is related with direct marketing campaigns of a Portuguese banking institution. The marketing campaigns were based on phone calls. Often, more than one contact to the same client was required, in order to access if the investment product would be or not subscribed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import (accuracy_score, confusion_matrix, \n",
    "                             classification_report, roc_auc_score)\n",
    "\n",
    "from plotting import (multiple_histograms_plot, plot_confusion_matrix, plot_roc)\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_context(\"notebook\", font_scale=1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/bank_marketing.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Segue uma descrição sucinta de cada uma das colunas do dataset:\n",
    "\n",
    "- `duration_seconds`: last contact duration, in seconds (numeric).\n",
    "\n",
    "- `duration_minutes`: last contact duration, in minutes (numeric).\n",
    "\n",
    "- `duration_hours`: last contact duration, in hours (numeric).\n",
    "\n",
    "- `emp.var.rate`: employment variation rate - quarterly indicator (numeric)\n",
    "\n",
    "- `nr.employed`: number of employees - quarterly indicator (numeric)\n",
    "\n",
    "- `euribor3m`: euribor 3 month rate - daily indicator (numeric)\n",
    "\n",
    "- `month`: last contact month of year (categorical: 'jan', 'feb', 'mar', ..., 'nov', 'dec')\n",
    "\n",
    "- `contact`: contact communication type (1 for cellular, 2 for telephone) \n",
    "\n",
    "- `loan`: has personal loan? (0 for no, 1 for yes)\n",
    "\n",
    "- `subscribed` - has the client subscribed a term deposit? (True, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparando os dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# crie a matriz 'X' sem month e o target\n",
    "<code>\n",
    "\n",
    "# crie o vetor 'y' com o target\n",
    "<code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# faça um train_test_split com 20% dos dados para teste\n",
    "# para podermos comparar os resultados entre nós, vamos sempre usar random_state=0\n",
    "\n",
    "X_train, X_test, y_train, y_test = <code>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aplicando a Regressão Logística"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogisticRegression(solver='lbfgs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# treine o modelo\n",
    "<code>\n",
    "\n",
    "# salve as predições do dataset de testes em 'y_pred'\n",
    "<code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calcule e imprima a acurácia\n",
    "<code>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Avaliação do modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matriz de Confusão, Precisão, Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imprima a matriz de confusao com a função 'confusion_matrix'\n",
    "<code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imprima precisão, recall e f1-score com a função 'classification_report'\n",
    "<code>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utilizando as probabilidades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calcule as probabilidades de investimento com o método 'predict_proba'\n",
    "# salve em 'y_pred_proba'\n",
    "<code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_proba = y_pred_proba[:, 1]\n",
    "y_pred_proba[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictions_hist(y_pred_proba, y_test, density=True):\n",
    "    preds_df = pd.DataFrame(data=[y_pred_proba, y_test.astype(str)],\n",
    "                            index=['Prediction', 'True Value']).T\n",
    "\n",
    "    preds_df['Prediction'] = preds_df['Prediction'].astype(float)\n",
    "    preds_df['True Value'] = preds_df['True Value'].astype(str)\n",
    "\n",
    "    multiple_histograms_plot(data=preds_df, x='Prediction', hue='True Value',\n",
    "                             bins=np.arange(0, 1.1, 0.025), density=density, probability_hist=True)\n",
    "\n",
    "    return preds_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_df = predictions_hist(y_pred_proba, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# você gostaria de aumentar o recall ou a precisão?\n",
    "# recalcule a matriz de confusão e o classification report com um threshold customizado\n",
    "<code>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outras métricas populares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imprima o AUC com a função 'roc_auc_score'\n",
    "<code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auc_test = plot_roc(y_test, y_pred_proba)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identificação de overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calcule predições para o dataset de treino\n",
    "<code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imprima os AUCs de treino e de teste para comparação\n",
    "<code>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tentando melhorar o modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nesta seção, vamos aplicar algumas técnicas que podem resultar em melhores resultados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tratamento de outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vamos setar a duração máxima de uma call para 3000 segundos\n",
    "# ou seja, se uma call exceder a duração máxima, edite os valores de acordo\n",
    "\n",
    "# atenção: é uma boa prática criar uma cópia da estrutura de dados ao invés de modificar a original\n",
    "# crie uma cópia de 'df' chamada 'df_no_outliers'\n",
    "\n",
    "<code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# faça um novo train-test-split\n",
    "# chame as variáveis de: X_train_no_outliers, X_test_no_outliers, y_train_no_outliers, y_test_no_outliers\n",
    "<code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogisticRegression(solver='lbfgs')\n",
    "logreg.fit(X_train_no_outliers, y_train_no_outliers)\n",
    "y_pred_proba_no_outliers = logreg.predict_proba(X_test_no_outliers)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plot_roc(y_test, y_pred_proba_no_outliers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = predictions_hist(y_pred_proba_no_outliers, y_test_no_outliers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusion_matrix_report(y_test, y_pred_proba, thres=0.5):\n",
    "    y_pred_proba_customizado = y_pred_proba >= thres\n",
    "    print(classification_report(y_test, y_pred_proba_customizado))\n",
    "    plot_confusion_matrix(y_test_no_outliers, y_pred_proba_customizado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# utilize a função 'confusion_matrix_report' com um threshold que \n",
    "# otimize a precisão e o recall\n",
    "<code>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lidando com classes desbalanceadas (parâmetro `class_weight`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# crie um objeto da classe LogisticRegression setando o parâmetro\n",
    "# 'class_weight' com 'balanced'\n",
    "<code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg.fit(X_train_no_outliers, y_train_no_outliers)\n",
    "y_pred_proba_class_weight = logreg.predict_proba(X_test_no_outliers)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plot_roc(y_test_no_outliers, y_pred_proba_class_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = predictions_hist(y_pred_proba_class_weight, y_test_no_outliers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# utilize a função 'confusion_matrix_report' com um threshold que \n",
    "# otimize a precisão e o recall\n",
    "<code>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Padronização/normalização dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vamos padronizar/normalizar as features com o StandardScaler\n",
    "# pra isso, vamos utilizar o método 'fit_transform' e chamar o resultado de 'scaled_data'\n",
    "<code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# agora vamos criar um DataFrame juntando as features padronizadas com o target\n",
    "X_scaled = pd.DataFrame(scaled_data, \n",
    "                        index=X_no_outliers.index,\n",
    "                        columns=X_no_outliers.columns)\n",
    "\n",
    "df_standardized = pd.concat([X_scaled, y_no_outliers],\n",
    "                            axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_standardized.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train_standardized, X_test_standardized, \n",
    " y_train_standardized, y_test_standardized) = train_test_split(X_scaled, y_no_outliers, \n",
    "                                                               test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogisticRegression(solver='lbfgs', class_weight='balanced')\n",
    "logreg.fit(X_train_standardized, y_train_standardized)\n",
    "y_pred_proba_standardized = logreg.predict_proba(X_test_standardized)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plot_roc(y_test_no_outliers, y_pred_proba_standardized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = predictions_hist(y_pred_proba_standardized, y_test_no_outliers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# utilize a função 'confusion_matrix_report' com um threshold que \n",
    "# otimize a precisão e o recall\n",
    "<code>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Salvando o modelo\n",
    "\n",
    "Vamos salvar o modelo para conseguirmos carregá-lo em análises futuras pós-aula. Para detalhes, veja a documentação do scikit-learn: [Model Persistence](http://scikit-learn.org/stable/modules/model_persistence.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = joblib.dump(logreg, '../models/logreg.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos também salvar o dataset transformado, assim como foi utilizado pelo modelo final."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(df_no_outliers.drop(columns='month')\n",
    "               .to_csv('../data/bank_marketing_processed.csv', index=False))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
